{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the K-NN algorithm for classification of iris\n",
    "\n",
    "In this assigment, you will classify if an Iris is 'Iris Setosa' or 'Iris Versicolour' or 'Iris Virginica' using the k nearest neighbor algorithm.\n",
    "\n",
    "The training data is from the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/iris.  Please download the dataset before running the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, understanding, and cleaning the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length[cm]</th>\n",
       "      <th>sepal width[cm]</th>\n",
       "      <th>petal length[cm]</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length[cm]  sepal width[cm]  petal length[cm]  petal width  \\\n",
       "0               5.1              3.5               1.4          0.2   \n",
       "1               4.9              3.0               1.4          0.2   \n",
       "2               4.7              3.2               1.3          0.2   \n",
       "3               4.6              3.1               1.5          0.2   \n",
       "4               5.0              3.6               1.4          0.2   \n",
       "\n",
       "         label  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the usual libraries\n",
    "import matplotlib.pyplot as plt # plotting utilities \n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd  # To read in the dataset we will use the Panda's library\n",
    "df = pd.read_csv('iris.csv', header=None, names = [\"sepal length[cm]\",\"sepal width[cm]\",\"petal length[cm]\", \"petal width\", \"label\"])\n",
    "\n",
    "# Next we observe the first 5 rows of the data to ensure everything was read correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocesssing\n",
    "It would be more convenient if the labels were integers instead of 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.  This way our code can always work with numerical values instead of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length[cm]</th>\n",
       "      <th>sepal width[cm]</th>\n",
       "      <th>petal length[cm]</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length[cm]  sepal width[cm]  petal length[cm]  petal width  label\n",
       "0               5.1              3.5               1.4          0.2      0\n",
       "1               4.9              3.0               1.4          0.2      0\n",
       "2               4.7              3.2               1.3          0.2      0\n",
       "3               4.6              3.1               1.5          0.2      0\n",
       "4               5.0              3.6               1.4          0.2      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'Iris-setosa': 0,\n",
    "              'Iris-versicolor': 1,\n",
    "              'Iris-virginica': 2})\n",
    "df.head()# Again, lets observe the first 5 rows to make sure everything worked before we continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples:  112\n",
      "The number of test exampels:  38\n",
      "The first four training labels\n",
      "[1 1 2 0]\n",
      "The first four iris' measurements\n",
      "[[5.8 2.4]\n",
      " [6.  1. ]\n",
      " [5.5 0.2]\n",
      " [7.3 1.8]]\n"
     ]
    }
   ],
   "source": [
    "# This time we will use sklearn's method for seperating the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "names = [\"sepal length[cm]\",\"petal width\"]\n",
    "#After completing the assignment, try your code with all the features\n",
    "#names = [\"sepal length[cm]\",\"sepal width[cm]\",\"petal length[cm]\", \"petal width\"]\n",
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df[names],df['label'], random_state=0)\n",
    "\n",
    "X_train=df_X_train.to_numpy()\n",
    "X_test=df_X_test.to_numpy()\n",
    "y_train=df_y_train.to_numpy()\n",
    "y_test=df_y_test.to_numpy()\n",
    "\n",
    "#Looking at the train/test split\n",
    "print(\"The number of training examples: \", X_train.shape[0])\n",
    "print(\"The number of test exampels: \", X_test.shape[0])\n",
    "\n",
    "print(\"The first four training labels\")\n",
    "print(y_train[0:4])\n",
    "\n",
    "print(\"The first four iris' measurements\")\n",
    "print(X_test[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing the data set\n",
    "\n",
    "Using a scatter plot to visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_names=['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
    "for i in range(0,3):\n",
    "    plt.scatter(X_train[y_train == i, 0],\n",
    "                X_train[y_train == i, 1],\n",
    "            marker='o',\n",
    "            label='class '+ str(i)+ ' '+ iris_names[i])\n",
    "\n",
    "plt.xlabel('sepal width[cm]')\n",
    "plt.ylabel('petal length[cm]')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "  #### TO-DO #####\n",
    "    \n",
    "    distance=np.empty(shape=[0, 2])\n",
    "    for i in range(np.size(y_train)):\n",
    "        a= (x1-X_train[i][0])\n",
    "        b= (x2-X_train[i][1])\n",
    "        c= np.sqrt(np.power(a,2)+ np.power(b,2))\n",
    "        distance=np.append(distance,np.array([[c,y_train[i]]]),axis=0)\n",
    "                \n",
    "    return  distance\n",
    "  ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x1,x2):\n",
    "    manhattan=np.empty(shape=[0, 2])\n",
    "    for i in range(np.size(y_train)):\n",
    "        a= abs(x1-X_train[i][0])\n",
    "        b= abs(x2-X_train[i][1])\n",
    "        manhattan=np.append(manhattan,np.array([[a+b,y_train[i]]]),axis=0)\n",
    "    \n",
    "    return manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors( X, y, x_test, k, distance= euclidean_distance):\n",
    "  #### TO-DO #####    \n",
    "\n",
    "##returning the label of the closest neighbor\n",
    "\n",
    "    distance_array=np.empty(shape=[0, 2])\n",
    "    sorted_array=np.empty(shape=[0, 2])\n",
    "    neighbors=np.empty(shape=[0, 1])\n",
    "    for i in range(np.size(y_test)):\n",
    "        distance_array = distance(x_test[i][0],x_test[i][1])\n",
    "        ##sorting the distance array in ascending order \n",
    "        sorted_array=distance_array[distance_array[:,0].argsort()]\n",
    "        if(k==1):\n",
    "            neighbors=np.append(neighbors,sorted_array[0,1])\n",
    "        elif(k>1):\n",
    "            f1=0\n",
    "            f2=0\n",
    "            f3=0\n",
    "            for j in range(k):\n",
    "                if(sorted_array[j][1]==0):\n",
    "                    f1+=1\n",
    "                elif(sorted_array[j][1]==1):\n",
    "                    f2+=1\n",
    "                else:\n",
    "                    f3+=1;\n",
    "            if (f1> f2) & (f1>f3):\n",
    "                neighbors=np.append(neighbors,0)\n",
    "            elif (f2>f1) & (f2>f3):\n",
    "                neighbors=np.append(neighbors,1)\n",
    "            else:\n",
    "                neighbors=np.append(neighbors,2)\n",
    "    \n",
    "  ##############\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #### TO-DO ##### \n",
    "#function to calculate accuracy\n",
    "def accuracy(actual_y,predicted_y):\n",
    "    correct_prediction=0\n",
    "    for i in range(np.size(actual_y)):\n",
    "        if(actual_y[i]==predicted_y[i]):\n",
    "            correct_prediction+=1\n",
    "    total_prediction=np.size(actual_y)\n",
    "    print(\"correct prediction:\",correct_prediction)\n",
    "    accuracy=(correct_prediction/total_prediction)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_R_classfier(x_train,x_test,y_train,y_test):\n",
    "    class1=0\n",
    "    class2=0\n",
    "    class3=0\n",
    "    zero_r_array=np.empty(shape=[0, 1])\n",
    "    for i in range(np.size(y_train)):\n",
    "        if(y_train[i]==0):\n",
    "            class1+=1\n",
    "        elif (y_train[i]==1):\n",
    "            class2+=1\n",
    "        elif (y_train[i]==2):\n",
    "            class3+=1\n",
    "    for j in range(np.size(y_test)):\n",
    "        if(class1>class2)& (class1>class3):\n",
    "            zero_r_array=np.append(zero_r_array,0)\n",
    "        elif(class2>class1)& (class2>class3):\n",
    "            zero_r_array=np.append(zero_r_array,1)\n",
    "        else:\n",
    "            zero_r_array=np.append(zero_r_array,2)\n",
    "       \n",
    "\n",
    "    return zero_r_array        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance_classifier(X, y, x_test, k, dist= manhattan_distance):\n",
    "    \n",
    "    ##returning the label of the closest neighbor\n",
    "\n",
    "    manhattan_distance_array=np.empty(shape=[0, 2])\n",
    "    manhattan_sorted_array=np.empty(shape=[0, 2])\n",
    "    manhattan_neighbors=np.empty(shape=[0, 1])\n",
    "    for i in range(np.size(y_test)):\n",
    "        manhattan_distance_array = dist(x_test[i][0],x_test[i][1])\n",
    "        ##sorting the distance array in ascending order \n",
    "        manhattan_sorted_array=manhattan_distance_array[manhattan_distance_array[:,0].argsort()]\n",
    "        if(k==1):\n",
    "            manhattan_neighbors=np.append(manhattan_neighbors,manhattan_sorted_array[0,1])\n",
    "        elif(k>1):\n",
    "            f1=0\n",
    "            f2=0\n",
    "            f3=0\n",
    "            for j in range(k):\n",
    "                if(manhattan_sorted_array[j][1]==0):\n",
    "                    f1+=1\n",
    "                elif(manhattan_sorted_array[j][1]==1):\n",
    "                    f2+=1\n",
    "                else:\n",
    "                    f3+=1;\n",
    "            if (f1> f2) & (f1>f3):\n",
    "                manhattan_neighbors=np.append(manhattan_neighbors,0)\n",
    "            elif (f2>f1) & (f2>f3):\n",
    "                manhattan_neighbors=np.append(manhattan_neighbors,1)\n",
    "            else:\n",
    "                manhattan_neighbors=np.append(manhattan_neighbors,2)\n",
    "    \n",
    "  ##############\n",
    "    return manhattan_neighbors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   2\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 36\n",
      "accuracy for k=1 is: 94.73684210526315 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   1\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 37\n",
      "accuracy for k=3 is: 97.36842105263158 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   1\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 37\n",
      "accuracy for k=5 is: 97.36842105263158 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   2\n",
      "5.50                 0.20               0                   2\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   2\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   2\n",
      "6.70                 1.50               1                   2\n",
      "6.80                 1.40               1                   2\n",
      "6.10                 1.30               1                   2\n",
      "6.10                 1.40               2                   2\n",
      "6.40                 1.50               1                   2\n",
      "6.10                 1.20               1                   2\n",
      "6.50                 1.50               1                   2\n",
      "6.10                 1.40               1                   2\n",
      "4.90                 0.10               0                   2\n",
      "6.00                 1.50               1                   2\n",
      "5.50                 1.20               1                   2\n",
      "4.80                 0.30               0                   2\n",
      "5.40                 0.40               0                   2\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   2\n",
      "4.80                 0.20               0                   2\n",
      "4.40                 0.20               0                   2\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   2\n",
      "5.10                 0.40               0                   2\n",
      "6.20                 1.30               1                   2\n",
      "5.00                 1.00               1                   2\n",
      "5.00                 0.40               0                   2\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   2\n",
      "5.20                 0.20               0                   2\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   2\n",
      "5.70                 0.30               0                   2\n",
      "6.00                 1.60               1                   2\n",
      "correct prediction: 9\n",
      "accuracy for zero-R classifier is: 23.684210526315788 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   2\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 36\n",
      "accuracy for manhattan distance and k=1 is: 94.73684210526315 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   1\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 37\n",
      "accuracy for manhattan distance and k=3 is: 97.36842105263158 %\n",
      "\n",
      "sepal width[cm]  petal length[cm]   Actual Class         Predicted Class\n",
      "5.80                 2.40               2                   2\n",
      "6.00                 1.00               1                   1\n",
      "5.50                 0.20               0                   0\n",
      "7.30                 1.80               2                   2\n",
      "5.00                 0.20               0                   0\n",
      "6.30                 2.50               2                   2\n",
      "5.00                 0.30               0                   0\n",
      "6.70                 1.50               1                   1\n",
      "6.80                 1.40               1                   1\n",
      "6.10                 1.30               1                   1\n",
      "6.10                 1.40               2                   1\n",
      "6.40                 1.50               1                   1\n",
      "6.10                 1.20               1                   1\n",
      "6.50                 1.50               1                   1\n",
      "6.10                 1.40               1                   1\n",
      "4.90                 0.10               0                   0\n",
      "6.00                 1.50               1                   1\n",
      "5.50                 1.20               1                   1\n",
      "4.80                 0.30               0                   0\n",
      "5.40                 0.40               0                   0\n",
      "5.60                 2.00               2                   2\n",
      "5.60                 1.50               1                   1\n",
      "4.80                 0.20               0                   0\n",
      "4.40                 0.20               0                   0\n",
      "6.20                 1.80               2                   2\n",
      "4.60                 0.20               0                   0\n",
      "5.10                 0.40               0                   0\n",
      "6.20                 1.30               1                   1\n",
      "5.00                 1.00               1                   1\n",
      "5.00                 0.40               0                   0\n",
      "6.40                 1.80               2                   2\n",
      "5.40                 1.50               1                   1\n",
      "5.20                 0.20               0                   0\n",
      "6.10                 1.80               2                   2\n",
      "6.40                 2.20               2                   2\n",
      "5.20                 1.40               1                   1\n",
      "5.70                 0.30               0                   0\n",
      "6.00                 1.60               1                   1\n",
      "correct prediction: 37\n",
      "accuracy for manhattan distance and k=5 is: 97.36842105263158 %\n"
     ]
    }
   ],
   "source": [
    "# FOR k=1 , implementing knn -\n",
    "\n",
    "result=get_neighbors(X_train,y_train,X_test,1)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result[i].astype(int)))\n",
    "print(\"accuracy for k=1 is:\",accuracy(y_test,result),\"%\")\n",
    "\n",
    "# For k=3, implementing knn -\n",
    "\n",
    "result2=get_neighbors(X_train,y_train,X_test,3)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result2[i].astype(int)))\n",
    "print(\"accuracy for k=3 is:\",accuracy(y_test,result2),\"%\")\n",
    "\n",
    "# For k=5, implementing knn -\n",
    "\n",
    "result3=get_neighbors(X_train,y_train,X_test,5)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result3[i].astype(int)))\n",
    "print(\"accuracy for k=5 is:\",accuracy(y_test,result3),\"%\")\n",
    "\n",
    "      \n",
    "#implementing zero-R classifier \n",
    "\n",
    "result4=zero_R_classfier(X_train,X_test,y_train,y_test)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result4[i].astype(int)))\n",
    "print(\"accuracy for zero-R classifier is:\",accuracy(y_test,result4),\"%\")\n",
    "    \n",
    "\n",
    "#implemmenting using manhattan distance - and k=1\n",
    "\n",
    "result5=manhattan_distance_classifier(X_train,y_train,X_test,1)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result5[i].astype(int)))\n",
    "print(\"accuracy for manhattan distance and k=1 is:\",accuracy(y_test,result5),\"%\")\n",
    "\n",
    "\n",
    "#implemmenting using manhattan distance - and k=3\n",
    "\n",
    "result6=manhattan_distance_classifier(X_train,y_train,X_test,3)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result6[i].astype(int)))\n",
    "print(\"accuracy for manhattan distance and k=3 is:\",accuracy(y_test,result6),\"%\")\n",
    "\n",
    "#implemmenting using manhattan distance - and k=5\n",
    "\n",
    "result7=manhattan_distance_classifier(X_train,y_train,X_test,3)\n",
    "print('\\n{:<10s}{:>18s}{:>15s}{:>24s}'.format(\"sepal width[cm]\",\"petal length[cm]\",\"Actual Class\",\"Predicted Class\"))\n",
    "for i in range(np.size(y_test)):\n",
    "    print('{:<10.2f}{:>15.2f}{:>16d}{:>20d}'.format(X_test[i][0],X_test[i][1],y_test[i],result7[i].astype(int)))\n",
    "print(\"accuracy for manhattan distance and k=5 is:\",accuracy(y_test,result7),\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
